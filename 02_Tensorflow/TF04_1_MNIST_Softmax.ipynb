{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 200 #전체 데이터를 200번 학습하겠다\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-e6af876c1f34>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10])) #784 개를 10개씩 찍는거임\n",
    "b = tf.Variable(tf.random_normal([10])) #bias는 조금씩 더해서 보정을 해줌\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b #그리고 가설을 세움 w가 선의 갯수 7840 개 x는 784개 \n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y)) #이걸하면 더 정확도 올라가는데 이유는 다음에\n",
    "#cost = tf.reduce_mean(tf.square(hypothesis - Y)) #내가 세운가설이랑 레이블이랑 빼서 같으면 됨\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) #옵티마이저한테 cost줄여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 6.452298981\n",
      "Epoch: 0002 cost = 2.135692006\n",
      "Epoch: 0003 cost = 1.312084718\n",
      "Epoch: 0004 cost = 0.993566674\n",
      "Epoch: 0005 cost = 0.830869656\n",
      "Epoch: 0006 cost = 0.725916094\n",
      "Epoch: 0007 cost = 0.657360490\n",
      "Epoch: 0008 cost = 0.604344100\n",
      "Epoch: 0009 cost = 0.565174859\n",
      "Epoch: 0010 cost = 0.530786024\n",
      "Epoch: 0011 cost = 0.507723715\n",
      "Epoch: 0012 cost = 0.484095692\n",
      "Epoch: 0013 cost = 0.461488594\n",
      "Epoch: 0014 cost = 0.449357647\n",
      "Epoch: 0015 cost = 0.436019531\n",
      "Epoch: 0016 cost = 0.418966990\n",
      "Epoch: 0017 cost = 0.410329099\n",
      "Epoch: 0018 cost = 0.399405501\n",
      "Epoch: 0019 cost = 0.389678343\n",
      "Epoch: 0020 cost = 0.381150303\n",
      "Epoch: 0021 cost = 0.375336516\n",
      "Epoch: 0022 cost = 0.369129499\n",
      "Epoch: 0023 cost = 0.359342335\n",
      "Epoch: 0024 cost = 0.354430613\n",
      "Epoch: 0025 cost = 0.347238408\n",
      "Epoch: 0026 cost = 0.345840585\n",
      "Epoch: 0027 cost = 0.337966744\n",
      "Epoch: 0028 cost = 0.337775454\n",
      "Epoch: 0029 cost = 0.327502263\n",
      "Epoch: 0030 cost = 0.327015193\n",
      "Epoch: 0031 cost = 0.321500745\n",
      "Epoch: 0032 cost = 0.321264572\n",
      "Epoch: 0033 cost = 0.313697343\n",
      "Epoch: 0034 cost = 0.312943959\n",
      "Epoch: 0035 cost = 0.310608109\n",
      "Epoch: 0036 cost = 0.308283296\n",
      "Epoch: 0037 cost = 0.300552881\n",
      "Epoch: 0038 cost = 0.302504129\n",
      "Epoch: 0039 cost = 0.298372087\n",
      "Epoch: 0040 cost = 0.296249306\n",
      "Epoch: 0041 cost = 0.297022560\n",
      "Epoch: 0042 cost = 0.292686606\n",
      "Epoch: 0043 cost = 0.287490969\n",
      "Epoch: 0044 cost = 0.288608462\n",
      "Epoch: 0045 cost = 0.283980315\n",
      "Epoch: 0046 cost = 0.287465741\n",
      "Epoch: 0047 cost = 0.281532600\n",
      "Epoch: 0048 cost = 0.281096129\n",
      "Epoch: 0049 cost = 0.279149858\n",
      "Epoch: 0050 cost = 0.278661022\n",
      "Epoch: 0051 cost = 0.274250230\n",
      "Epoch: 0052 cost = 0.277692624\n",
      "Epoch: 0053 cost = 0.272393932\n",
      "Epoch: 0054 cost = 0.272182214\n",
      "Epoch: 0055 cost = 0.271579295\n",
      "Epoch: 0056 cost = 0.268391793\n",
      "Epoch: 0057 cost = 0.268489807\n",
      "Epoch: 0058 cost = 0.265585468\n",
      "Epoch: 0059 cost = 0.267263611\n",
      "Epoch: 0060 cost = 0.267532619\n",
      "Epoch: 0061 cost = 0.262803536\n",
      "Epoch: 0062 cost = 0.262583405\n",
      "Epoch: 0063 cost = 0.261397720\n",
      "Epoch: 0064 cost = 0.259899184\n",
      "Epoch: 0065 cost = 0.261802542\n",
      "Epoch: 0066 cost = 0.258317320\n",
      "Epoch: 0067 cost = 0.259540191\n",
      "Epoch: 0068 cost = 0.256852129\n",
      "Epoch: 0069 cost = 0.254833450\n",
      "Epoch: 0070 cost = 0.258985675\n",
      "Epoch: 0071 cost = 0.252960362\n",
      "Epoch: 0072 cost = 0.255774289\n",
      "Epoch: 0073 cost = 0.252405949\n",
      "Epoch: 0074 cost = 0.254101873\n",
      "Epoch: 0075 cost = 0.251079755\n",
      "Epoch: 0076 cost = 0.252041753\n",
      "Epoch: 0077 cost = 0.252047290\n",
      "Epoch: 0078 cost = 0.250080503\n",
      "Epoch: 0079 cost = 0.247407297\n",
      "Epoch: 0080 cost = 0.249514510\n",
      "Epoch: 0081 cost = 0.247087747\n",
      "Epoch: 0082 cost = 0.249179533\n",
      "Epoch: 0083 cost = 0.246126067\n",
      "Epoch: 0084 cost = 0.248659381\n",
      "Epoch: 0085 cost = 0.246555521\n",
      "Epoch: 0086 cost = 0.242967752\n",
      "Epoch: 0087 cost = 0.244460378\n",
      "Epoch: 0088 cost = 0.243901023\n",
      "Epoch: 0089 cost = 0.246057063\n",
      "Epoch: 0090 cost = 0.242126383\n",
      "Epoch: 0091 cost = 0.242273198\n",
      "Epoch: 0092 cost = 0.241889485\n",
      "Epoch: 0093 cost = 0.244546482\n",
      "Epoch: 0094 cost = 0.236024918\n",
      "Epoch: 0095 cost = 0.246079578\n",
      "Epoch: 0096 cost = 0.237691954\n",
      "Epoch: 0097 cost = 0.242212566\n",
      "Epoch: 0098 cost = 0.238147507\n",
      "Epoch: 0099 cost = 0.242194700\n",
      "Epoch: 0100 cost = 0.237187071\n",
      "Epoch: 0101 cost = 0.240097432\n",
      "Epoch: 0102 cost = 0.239665089\n",
      "Epoch: 0103 cost = 0.238840942\n",
      "Epoch: 0104 cost = 0.234905034\n",
      "Epoch: 0105 cost = 0.237021417\n",
      "Epoch: 0106 cost = 0.238012052\n",
      "Epoch: 0107 cost = 0.233442626\n",
      "Epoch: 0108 cost = 0.235681026\n",
      "Epoch: 0109 cost = 0.238466078\n",
      "Epoch: 0110 cost = 0.234858252\n",
      "Epoch: 0111 cost = 0.235512868\n",
      "Epoch: 0112 cost = 0.237060958\n",
      "Epoch: 0113 cost = 0.234149456\n",
      "Epoch: 0114 cost = 0.232757211\n",
      "Epoch: 0115 cost = 0.235935558\n",
      "Epoch: 0116 cost = 0.232729349\n",
      "Epoch: 0117 cost = 0.234423356\n",
      "Epoch: 0118 cost = 0.232647840\n",
      "Epoch: 0119 cost = 0.233784916\n",
      "Epoch: 0120 cost = 0.229017671\n",
      "Epoch: 0121 cost = 0.234398648\n",
      "Epoch: 0122 cost = 0.231593637\n",
      "Epoch: 0123 cost = 0.226939791\n",
      "Epoch: 0124 cost = 0.233562971\n",
      "Epoch: 0125 cost = 0.232362583\n",
      "Epoch: 0126 cost = 0.228961995\n",
      "Epoch: 0127 cost = 0.233798581\n",
      "Epoch: 0128 cost = 0.229731569\n",
      "Epoch: 0129 cost = 0.227129436\n",
      "Epoch: 0130 cost = 0.232683695\n",
      "Epoch: 0131 cost = 0.230463309\n",
      "Epoch: 0132 cost = 0.230102563\n",
      "Epoch: 0133 cost = 0.231398423\n",
      "Epoch: 0134 cost = 0.223114327\n",
      "Epoch: 0135 cost = 0.234644250\n",
      "Epoch: 0136 cost = 0.228116795\n",
      "Epoch: 0137 cost = 0.228033131\n",
      "Epoch: 0138 cost = 0.227698368\n",
      "Epoch: 0139 cost = 0.227716548\n",
      "Epoch: 0140 cost = 0.225243610\n",
      "Epoch: 0141 cost = 0.230282964\n",
      "Epoch: 0142 cost = 0.222067321\n",
      "Epoch: 0143 cost = 0.229226227\n",
      "Epoch: 0144 cost = 0.229967007\n",
      "Epoch: 0145 cost = 0.229506643\n",
      "Epoch: 0146 cost = 0.225557921\n",
      "Epoch: 0147 cost = 0.223193944\n",
      "Epoch: 0148 cost = 0.223506050\n",
      "Epoch: 0149 cost = 0.232029995\n",
      "Epoch: 0150 cost = 0.227416971\n",
      "Epoch: 0151 cost = 0.222311978\n",
      "Epoch: 0152 cost = 0.227984217\n",
      "Epoch: 0153 cost = 0.223776785\n",
      "Epoch: 0154 cost = 0.226772202\n",
      "Epoch: 0155 cost = 0.223116252\n",
      "Epoch: 0156 cost = 0.224752601\n",
      "Epoch: 0157 cost = 0.225527970\n",
      "Epoch: 0158 cost = 0.224836914\n",
      "Epoch: 0159 cost = 0.222493705\n",
      "Epoch: 0160 cost = 0.226518571\n",
      "Epoch: 0161 cost = 0.226174166\n",
      "Epoch: 0162 cost = 0.221431432\n",
      "Epoch: 0163 cost = 0.226835714\n",
      "Epoch: 0164 cost = 0.221431662\n",
      "Epoch: 0165 cost = 0.225064865\n",
      "Epoch: 0166 cost = 0.222384392\n",
      "Epoch: 0167 cost = 0.222415454\n",
      "Epoch: 0168 cost = 0.224819953\n",
      "Epoch: 0169 cost = 0.224582687\n",
      "Epoch: 0170 cost = 0.222905207\n",
      "Epoch: 0171 cost = 0.222568602\n",
      "Epoch: 0172 cost = 0.220801339\n",
      "Epoch: 0173 cost = 0.226622363\n",
      "Epoch: 0174 cost = 0.224161842\n",
      "Epoch: 0175 cost = 0.218716312\n",
      "Epoch: 0176 cost = 0.220692737\n",
      "Epoch: 0177 cost = 0.222579116\n",
      "Epoch: 0178 cost = 0.220796254\n",
      "Epoch: 0179 cost = 0.224441491\n",
      "Epoch: 0180 cost = 0.221060587\n",
      "Epoch: 0181 cost = 0.222622013\n",
      "Epoch: 0182 cost = 0.216607607\n",
      "Epoch: 0183 cost = 0.222544056\n",
      "Epoch: 0184 cost = 0.219965225\n",
      "Epoch: 0185 cost = 0.224465744\n",
      "Epoch: 0186 cost = 0.221779186\n",
      "Epoch: 0187 cost = 0.218238051\n",
      "Epoch: 0188 cost = 0.221269568\n",
      "Epoch: 0189 cost = 0.219992590\n",
      "Epoch: 0190 cost = 0.220109275\n",
      "Epoch: 0191 cost = 0.221963432\n",
      "Epoch: 0192 cost = 0.220690752\n",
      "Epoch: 0193 cost = 0.216482790\n",
      "Epoch: 0194 cost = 0.222121855\n",
      "Epoch: 0195 cost = 0.222403702\n",
      "Epoch: 0196 cost = 0.221621639\n",
      "Epoch: 0197 cost = 0.216585886\n",
      "Epoch: 0198 cost = 0.219871645\n",
      "Epoch: 0199 cost = 0.219412731\n",
      "Epoch: 0200 cost = 0.223238135\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    vc.append(avg_cost)\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22817e0b7b8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'bool'>\n",
      "Accuracy (test): 0.9247\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# 정확도 확인하기\n",
    "# Test model and check accuracy\n",
    "pred = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "print (pred.dtype)\n",
    "accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "print('Accuracy (test):', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도가 85%\n",
    "# 두번째 cost식으로 했더니 정확도가 92%로 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
